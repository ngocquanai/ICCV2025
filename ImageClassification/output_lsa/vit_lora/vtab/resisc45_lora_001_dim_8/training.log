2025-03-08 15:13:21,195 - training - INFO - Namespace(config_folder='configs_LS', dataset='resisc45', dpr=0.1, eval='True', lr=0.005, model='vit_base_patch16_224_in21k_lora', model_checkpoint='/lustre/scratch/client/movian/research/users/quanpn2/Parameter-Efficient-Transfer-Learning-Benchmark/ImageClassification/ViT-B_16.npz', model_type='vit_lora', output='output_lsa', seed=42, task='vtab', topN=8, tuning_mode='lora', wd=0.005)
2025-03-08 15:13:21,196 - training - INFO - {'name': 'resisc45_lora_001', 'class_num': 45, 'train_aug': True, 'topN': 96, 'labelsmoothing': 0.1, 'batch_size': 64, 'epochs': 5, 'warmup_epochs': 10, 'custom_loss': False}
2025-03-08 15:13:21,229 - training - INFO - Data transform, train:
Compose(
    Resize(size=(224, 224), interpolation=bicubic, max_size=None, antialias=None)
    RandomHorizontalFlip(p=0.5)
    RandAugment(n=2, ops=
	AugmentOp(name=AutoContrast, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Equalize, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Invert, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=Rotate, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=PosterizeIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SolarizeIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SolarizeAdd, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ColorIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ContrastIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=BrightnessIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=SharpnessIncreasing, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ShearX, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=ShearY, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=TranslateXRel, p=0.5, m=9, mstd=0.5)
	AugmentOp(name=TranslateYRel, p=0.5, m=9, mstd=0.5))
    ToTensor()
    Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))
)
2025-03-08 15:13:21,230 - training - INFO - Data transform, test:
Compose(
    Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=None)
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)
2025-03-08 15:13:23,104 - training - INFO - VisionTransformer_lora(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
    (norm): Identity()
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (blocks): Sequential(
    (0): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (linear_a_q): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_q): Linear(in_features=8, out_features=768, bias=False)
        (linear_a_v): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_v): Linear(in_features=8, out_features=768, bias=False)
      )
      (ls1): Identity()
      (drop_path1): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): Identity()
    )
    (1): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (linear_a_q): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_q): Linear(in_features=8, out_features=768, bias=False)
        (linear_a_v): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_v): Linear(in_features=8, out_features=768, bias=False)
      )
      (ls1): Identity()
      (drop_path1): DropPath(drop_prob=0.009)
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): DropPath(drop_prob=0.009)
    )
    (2): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (linear_a_q): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_q): Linear(in_features=8, out_features=768, bias=False)
        (linear_a_v): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_v): Linear(in_features=8, out_features=768, bias=False)
      )
      (ls1): Identity()
      (drop_path1): DropPath(drop_prob=0.018)
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): DropPath(drop_prob=0.018)
    )
    (3): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (linear_a_q): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_q): Linear(in_features=8, out_features=768, bias=False)
        (linear_a_v): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_v): Linear(in_features=8, out_features=768, bias=False)
      )
      (ls1): Identity()
      (drop_path1): DropPath(drop_prob=0.027)
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): DropPath(drop_prob=0.027)
    )
    (4): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (linear_a_q): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_q): Linear(in_features=8, out_features=768, bias=False)
        (linear_a_v): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_v): Linear(in_features=8, out_features=768, bias=False)
      )
      (ls1): Identity()
      (drop_path1): DropPath(drop_prob=0.036)
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): DropPath(drop_prob=0.036)
    )
    (5): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (linear_a_q): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_q): Linear(in_features=8, out_features=768, bias=False)
        (linear_a_v): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_v): Linear(in_features=8, out_features=768, bias=False)
      )
      (ls1): Identity()
      (drop_path1): DropPath(drop_prob=0.045)
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): DropPath(drop_prob=0.045)
    )
    (6): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (linear_a_q): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_q): Linear(in_features=8, out_features=768, bias=False)
        (linear_a_v): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_v): Linear(in_features=8, out_features=768, bias=False)
      )
      (ls1): Identity()
      (drop_path1): DropPath(drop_prob=0.055)
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): DropPath(drop_prob=0.055)
    )
    (7): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (linear_a_q): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_q): Linear(in_features=8, out_features=768, bias=False)
        (linear_a_v): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_v): Linear(in_features=8, out_features=768, bias=False)
      )
      (ls1): Identity()
      (drop_path1): DropPath(drop_prob=0.064)
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): DropPath(drop_prob=0.064)
    )
    (8): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (linear_a_q): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_q): Linear(in_features=8, out_features=768, bias=False)
        (linear_a_v): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_v): Linear(in_features=8, out_features=768, bias=False)
      )
      (ls1): Identity()
      (drop_path1): DropPath(drop_prob=0.073)
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): DropPath(drop_prob=0.073)
    )
    (9): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (linear_a_q): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_q): Linear(in_features=8, out_features=768, bias=False)
        (linear_a_v): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_v): Linear(in_features=8, out_features=768, bias=False)
      )
      (ls1): Identity()
      (drop_path1): DropPath(drop_prob=0.082)
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): DropPath(drop_prob=0.082)
    )
    (10): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (linear_a_q): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_q): Linear(in_features=8, out_features=768, bias=False)
        (linear_a_v): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_v): Linear(in_features=8, out_features=768, bias=False)
      )
      (ls1): Identity()
      (drop_path1): DropPath(drop_prob=0.091)
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): DropPath(drop_prob=0.091)
    )
    (11): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
        (linear_a_q): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_q): Linear(in_features=8, out_features=768, bias=False)
        (linear_a_v): Linear(in_features=768, out_features=8, bias=False)
        (linear_b_v): Linear(in_features=8, out_features=768, bias=False)
      )
      (ls1): Identity()
      (drop_path1): DropPath(drop_prob=0.100)
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (drop1): Dropout(p=0.0, inplace=False)
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop2): Dropout(p=0.0, inplace=False)
      )
      (ls2): Identity()
      (drop_path2): DropPath(drop_prob=0.100)
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (fc_norm): Identity()
  (head): Linear(in_features=768, out_features=45, bias=True)
)
2025-03-08 15:13:23,104 - training - INFO - blocks.0.attn.linear_a_q.weight
2025-03-08 15:13:23,104 - training - INFO - blocks.0.attn.linear_b_q.weight
2025-03-08 15:13:23,104 - training - INFO - blocks.0.attn.linear_a_v.weight
2025-03-08 15:13:23,104 - training - INFO - blocks.0.attn.linear_b_v.weight
2025-03-08 15:13:23,105 - training - INFO - blocks.1.attn.linear_a_q.weight
2025-03-08 15:13:23,105 - training - INFO - blocks.1.attn.linear_b_q.weight
2025-03-08 15:13:23,105 - training - INFO - blocks.1.attn.linear_a_v.weight
2025-03-08 15:13:23,105 - training - INFO - blocks.1.attn.linear_b_v.weight
2025-03-08 15:13:23,105 - training - INFO - blocks.2.attn.linear_a_q.weight
2025-03-08 15:13:23,105 - training - INFO - blocks.2.attn.linear_b_q.weight
2025-03-08 15:13:23,105 - training - INFO - blocks.2.attn.linear_a_v.weight
2025-03-08 15:13:23,105 - training - INFO - blocks.2.attn.linear_b_v.weight
2025-03-08 15:13:23,105 - training - INFO - blocks.3.attn.linear_a_q.weight
2025-03-08 15:13:23,105 - training - INFO - blocks.3.attn.linear_b_q.weight
2025-03-08 15:13:23,105 - training - INFO - blocks.3.attn.linear_a_v.weight
2025-03-08 15:13:23,105 - training - INFO - blocks.3.attn.linear_b_v.weight
2025-03-08 15:13:23,105 - training - INFO - blocks.4.attn.linear_a_q.weight
2025-03-08 15:13:23,105 - training - INFO - blocks.4.attn.linear_b_q.weight
2025-03-08 15:13:23,105 - training - INFO - blocks.4.attn.linear_a_v.weight
2025-03-08 15:13:23,105 - training - INFO - blocks.4.attn.linear_b_v.weight
2025-03-08 15:13:23,105 - training - INFO - blocks.5.attn.linear_a_q.weight
2025-03-08 15:13:23,105 - training - INFO - blocks.5.attn.linear_b_q.weight
2025-03-08 15:13:23,105 - training - INFO - blocks.5.attn.linear_a_v.weight
2025-03-08 15:13:23,105 - training - INFO - blocks.5.attn.linear_b_v.weight
2025-03-08 15:13:23,105 - training - INFO - blocks.6.attn.linear_a_q.weight
2025-03-08 15:13:23,105 - training - INFO - blocks.6.attn.linear_b_q.weight
2025-03-08 15:13:23,105 - training - INFO - blocks.6.attn.linear_a_v.weight
2025-03-08 15:13:23,106 - training - INFO - blocks.6.attn.linear_b_v.weight
2025-03-08 15:13:23,106 - training - INFO - blocks.7.attn.linear_a_q.weight
2025-03-08 15:13:23,106 - training - INFO - blocks.7.attn.linear_b_q.weight
2025-03-08 15:13:23,106 - training - INFO - blocks.7.attn.linear_a_v.weight
2025-03-08 15:13:23,106 - training - INFO - blocks.7.attn.linear_b_v.weight
2025-03-08 15:13:23,106 - training - INFO - blocks.8.attn.linear_a_q.weight
2025-03-08 15:13:23,106 - training - INFO - blocks.8.attn.linear_b_q.weight
2025-03-08 15:13:23,106 - training - INFO - blocks.8.attn.linear_a_v.weight
2025-03-08 15:13:23,106 - training - INFO - blocks.8.attn.linear_b_v.weight
2025-03-08 15:13:23,106 - training - INFO - blocks.9.attn.linear_a_q.weight
2025-03-08 15:13:23,106 - training - INFO - blocks.9.attn.linear_b_q.weight
2025-03-08 15:13:23,106 - training - INFO - blocks.9.attn.linear_a_v.weight
2025-03-08 15:13:23,106 - training - INFO - blocks.9.attn.linear_b_v.weight
2025-03-08 15:13:23,106 - training - INFO - blocks.10.attn.linear_a_q.weight
2025-03-08 15:13:23,106 - training - INFO - blocks.10.attn.linear_b_q.weight
2025-03-08 15:13:23,106 - training - INFO - blocks.10.attn.linear_a_v.weight
2025-03-08 15:13:23,106 - training - INFO - blocks.10.attn.linear_b_v.weight
2025-03-08 15:13:23,106 - training - INFO - blocks.11.attn.linear_a_q.weight
2025-03-08 15:13:23,106 - training - INFO - blocks.11.attn.linear_b_q.weight
2025-03-08 15:13:23,106 - training - INFO - blocks.11.attn.linear_a_v.weight
2025-03-08 15:13:23,106 - training - INFO - blocks.11.attn.linear_b_v.weight
2025-03-08 15:13:23,106 - training - INFO - head.weight
2025-03-08 15:13:23,107 - training - INFO - head.bias
2025-03-08 15:13:23,107 - training - INFO - number of extra params: 329517
2025-03-08 15:13:23,107 - training - INFO - label smoothing
2025-03-08 15:13:31,440 - training - INFO - RAM used: 90160.042 memory: 6480.349MB TIME: 6.905
2025-03-08 15:13:43,159 - training - INFO - RAM used: 90179.628 memory: 6480.349MB TIME: 5.863
2025-03-08 15:13:54,809 - training - INFO - RAM used: 90173.582 memory: 6480.349MB TIME: 5.827
2025-03-08 15:14:12,884 - training - INFO - -------------------------------------------------- Current best acc: 0.3503174603174603 --------------------------------------------------
2025-03-08 15:14:12,884 - training - INFO - -------------------------------------------------- Current best ECE: 0.269 --------------------
2025-03-08 15:14:12,884 - training - INFO - 4 0.3503174603174603 memory: 6480.34912109375MB
2025-03-08 15:14:13,010 - training - INFO - end
